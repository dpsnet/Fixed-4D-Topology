"""
æ™®é€‚ç³»æ•° c1 æå–å™¨
Universal Coefficient c1 Extractor

ä»åˆ†å½¢æ•°æ®ä¸­æå– c1 = 1/4 å¹¶éªŒè¯æ ¸å¿ƒçŒœæƒ³
"""

import numpy as np
from typing import Dict, List, Tuple
import json
from datetime import datetime
from fractal_laplacian import FractalLaplacian, FractalMeasure, verify_c1_conjecture
from random_fractal_generator import RandomFractalGenerator
import warnings


class C1Extractor:
    """
    c1 æå–åˆ†æå™¨
    
    ä»»åŠ¡:
    1. ä»åˆ†å½¢æ•°æ®ä¸­æå–è°±ç»´åº¦æµ
    2. æ‹Ÿåˆæå– c1
    3. éªŒè¯ c1 = 1/4 çŒœæƒ³
    4. ç»Ÿè®¡åˆ†æ
    """
    
    def __init__(self, true_c1: float = 0.25):
        self.true_c1 = true_c1
        self.results = []
        
    def extract_from_fractal(self, points: np.ndarray, 
                             method: str = 'laplacian',
                             n_eigenvalues: int = 50) -> Dict:
        """
        ä»å•ä¸ªåˆ†å½¢æ ·æœ¬ä¸­æå– c1
        
        Args:
            points: åˆ†å½¢ç‚¹é›† (N, d)
            method: æå–æ–¹æ³• ('laplacian' æˆ– 'box_counting')
            n_eigenvalues: è®¡ç®—çš„ eigenvalue æ•°é‡
            
        Returns:
            æå–ç»“æœå­—å…¸
        """
        if method == 'laplacian':
            return self._extract_via_laplacian(points, n_eigenvalues)
        elif method == 'box_counting':
            return self._extract_via_box_counting(points)
        else:
            raise ValueError(f"Unknown method: {method}")
    
    def _extract_via_laplacian(self, points: np.ndarray, 
                                n_eigenvalues: int) -> Dict:
        """ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­æ–¹æ³•æå– c1"""
        
        fl = FractalLaplacian(dimension=points.shape[1])
        
        # æ„å»ºå›¾æ‹‰æ™®æ‹‰æ–¯
        try:
            L = fl.construct_graph_laplacian(points, epsilon=None)
        except Exception as e:
            return {'error': f'Laplacian construction failed: {e}', 'c1': np.nan}
        
        # è®¡ç®—è°±ç»´åº¦
        try:
            t_vals, d_s = fl.compute_spectral_dimension(L, n_eigenvalues=n_eigenvalues)
        except Exception as e:
            return {'error': f'Spectral dimension computation failed: {e}', 'c1': np.nan}
        
        # æå– c1
        result = fl.extract_c1_from_spectral_flow(t_vals, d_s)
        
        return result
    
    def _extract_via_box_counting(self, points: np.ndarray) -> Dict:
        """ä½¿ç”¨ç›’è®¡æ•°æ³•æå– c1"""
        
        fm = FractalMeasure(c1=self.true_c1)
        
        # è®¡ç®—ç›’è®¡æ•°ç»´åº¦
        eps_vals, d_f = fm.box_counting_dimension(points)
        
        # ä»åˆ†å½¢ç»´åº¦æµä¸­æå– c1
        # d_f(eps) = d_max - c1 / ln(eps/eps_0)
        
        valid_mask = (d_f > 1) & (d_f < 5) & (eps_vals > 0)
        eps_valid = eps_vals[valid_mask]
        d_f_valid = d_f[valid_mask]
        
        if len(eps_valid) < 5:
            return {'error': 'Insufficient data for box counting', 'c1': np.nan}
        
        # æ‹Ÿåˆ
        log_eps = np.log(eps_valid)
        x = 1.0 / log_eps
        y = d_f_valid
        
        # çº¿æ€§æ‹Ÿåˆ: y = d_max - c1 * x
        mask = np.abs(log_eps) > 0.1
        if np.sum(mask) < 5:
            mask = np.abs(log_eps) > 0.01
        
        x_fit = x[mask]
        y_fit = y[mask]
        
        A = np.vstack([x_fit, np.ones(len(x_fit))]).T
        try:
            c1_fit, d_max_fit = np.linalg.lstsq(A, y_fit, rcond=None)[0]
            c1_fit = -c1_fit
        except:
            return {'error': 'Fitting failed', 'c1': np.nan}
        
        # è®¡ç®— R^2
        y_pred = d_max_fit - c1_fit * x_fit
        ss_res = np.sum((y_fit - y_pred)**2)
        ss_tot = np.sum((y_fit - np.mean(y_fit))**2)
        r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0
        
        return {
            'c1': float(c1_fit),
            'd_max': float(d_max_fit),
            'quality': float(r_squared),
            'c1_error': abs(c1_fit - self.true_c1),
            'method': 'box_counting'
        }
    
    def analyze_dataset(self, fractal_data: List[np.ndarray],
                       method: str = 'laplacian') -> Dict:
        """
        åˆ†ææ•´ä¸ªåˆ†å½¢æ•°æ®é›†ï¼Œç»Ÿè®¡éªŒè¯ c1 = 1/4
        
        Args:
            fractal_data: åˆ†å½¢æ ·æœ¬åˆ—è¡¨
            method: æå–æ–¹æ³•
            
        Returns:
            ç»Ÿè®¡åˆ†æç»“æœ
        """
        print(f"åˆ†æ {len(fractal_data)} ä¸ªåˆ†å½¢æ ·æœ¬...")
        
        all_c1 = []
        all_d_max = []
        all_quality = []
        errors = []
        
        for i, points in enumerate(fractal_data):
            if i % 10 == 0:
                print(f"  è¿›åº¦: {i}/{len(fractal_data)}")
            
            result = self.extract_from_fractal(points, method=method)
            
            if 'error' in result:
                errors.append((i, result['error']))
                continue
            
            if not np.isnan(result.get('c1', np.nan)):
                all_c1.append(result['c1'])
                all_d_max.append(result.get('d_max', np.nan))
                all_quality.append(result.get('quality', 0))
        
        # ç»Ÿè®¡åˆ†æ
        all_c1 = np.array(all_c1)
        all_d_max = np.array(all_d_max)
        all_quality = np.array(all_quality)
        
        # è¿‡æ»¤å¼‚å¸¸å€¼
        valid_mask = (all_c1 > 0) & (all_c1 < 1) & (all_quality > 0.1)
        valid_c1 = all_c1[valid_mask]
        
        if len(valid_c1) == 0:
            return {
                'error': 'No valid c1 extracted',
                'total_samples': len(fractal_data),
                'failed_samples': len(errors)
            }
        
        mean_c1 = np.mean(valid_c1)
        std_c1 = np.std(valid_c1)
        sem_c1 = std_c1 / np.sqrt(len(valid_c1))  # æ ‡å‡†è¯¯
        
        # ä¸ç†è®ºå€¼çš„åå·®
        deviation = abs(mean_c1 - self.true_c1)
        n_sigma = deviation / sem_c1 if sem_c1 > 0 else np.inf
        
        # å‡è®¾æ£€éªŒ (c1 = 0.25)
        from scipy import stats
        t_stat, p_value = stats.ttest_1samp(valid_c1, self.true_c1)
        
        summary = {
            'total_samples': len(fractal_data),
            'successful_extractions': len(valid_c1),
            'failed_extractions': len(errors),
            'mean_c1': float(mean_c1),
            'std_c1': float(std_c1),
            'sem_c1': float(sem_c1),
            'ci_95': (float(mean_c1 - 1.96*sem_c1), float(mean_c1 + 1.96*sem_c1)),
            'true_c1': self.true_c1,
            'deviation_from_true': float(deviation),
            'n_sigma': float(n_sigma),
            't_statistic': float(t_stat),
            'p_value': float(p_value),
            'conjecture_verified': deviation < 2*sem_c1,  # åœ¨2 sigmaå†…
            'all_c1_values': valid_c1.tolist(),
            'mean_d_max': float(np.mean(all_d_max[valid_mask])) if len(all_d_max) > 0 else None,
            'mean_quality': float(np.mean(all_quality[valid_mask])) if len(all_quality) > 0 else None
        }
        
        return summary
    
    def print_report(self, summary: Dict):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("c1 = 1/4 çŒœæƒ³éªŒè¯æŠ¥å‘Š")
        print("=" * 70)
        
        if 'error' in summary:
            print(f"\nâŒ é”™è¯¯: {summary['error']}")
            return
        
        print(f"\nğŸ“Š æ ·æœ¬ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {summary['total_samples']}")
        print(f"   æˆåŠŸæå–: {summary['successful_extractions']}")
        print(f"   å¤±è´¥æå–: {summary['failed_extractions']}")
        
        print(f"\nğŸ“ˆ c1 æå–ç»“æœ:")
        print(f"   æå–çš„ c1: {summary['mean_c1']:.6f} Â± {summary['sem_c1']:.6f}")
        print(f"   æ ‡å‡†å·®: {summary['std_c1']:.6f}")
        print(f"   95% ç½®ä¿¡åŒºé—´: [{summary['ci_95'][0]:.6f}, {summary['ci_95'][1]:.6f}]")
        print(f"   ç†è®ºå€¼ c1: {summary['true_c1']:.6f}")
        
        print(f"\nâœ… éªŒè¯ç»“æœ:")
        print(f"   ä¸ç†è®ºå€¼åå·®: {summary['deviation_from_true']:.6f}")
        print(f"   n-sigma: {summary['n_sigma']:.2f}")
        print(f"   t-ç»Ÿè®¡é‡: {summary['t_statistic']:.4f}")
        print(f"   p-å€¼: {summary['p_value']:.4f}")
        
        if summary['conjecture_verified']:
            print(f"\n   ğŸ‰ ç»“è®º: çŒœæƒ³ c1 = 1/4 é€šè¿‡ç»Ÿè®¡éªŒè¯!")
        else:
            print(f"\n   âš ï¸ ç»“è®º: éœ€è¦æ›´å¤šæ•°æ®æˆ–æ”¹è¿›æå–æ–¹æ³•")
        
        if summary['mean_d_max']:
            print(f"\nğŸ“ åˆ†å½¢ç»´åº¦:")
            print(f"   å¹³å‡ d_max: {summary['mean_d_max']:.2f}")
            print(f"   å¹³å‡æ‹Ÿåˆè´¨é‡ R^2: {summary['mean_quality']:.4f}")
        
        print("=" * 70)
    
    def save_report(self, summary: Dict, filename: str):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        summary_save = {k: v for k, v in summary.items() if k != 'all_c1_values'}
        
        with open(filename, 'w') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'summary': summary_save
            }, f, indent=2)
        
        print(f"\næŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")


def run_full_analysis(n_samples: int = 100, n_points: int = 300):
    """
    è¿è¡Œå®Œæ•´çš„ c1 æå–åˆ†æ
    
    Args:
        n_samples: åˆ†å½¢æ ·æœ¬æ•°é‡
        n_points: æ¯ä¸ªæ ·æœ¬çš„ç‚¹æ•°
    """
    print("=" * 70)
    print(f"c1 = 1/4 çŒœæƒ³å®Œæ•´éªŒè¯åˆ†æ")
    print(f"æ ·æœ¬: {n_samples} x {n_points} ç‚¹")
    print("=" * 70)
    
    # 1. é¦–å…ˆéªŒè¯æ ¸å¿ƒçŒœæƒ³çš„ä¸€è‡´æ€§
    print("\n[1] éªŒè¯æ ¸å¿ƒçŒœæƒ³ä¸€è‡´æ€§")
    conjecture_result = verify_c1_conjecture(d_f_max=4.0, d_f_min=2.0)
    print(f"   c1 = 1/d_f^max = {conjecture_result['c1_from_reciprocal']:.6f}")
    print(f"   c1 = (d_f^min/d_f^max)^2 = {conjecture_result['c1_from_ratio_squared']:.6f}")
    print(f"   ä¸¤ä¸ªçŒœæƒ³ä¸€è‡´: {conjecture_result['conjectures_match']}")
    
    # 2. ç”Ÿæˆæµ‹è¯•æ•°æ®
    print("\n[2] ç”Ÿæˆåˆ†å½¢æ•°æ®é›†")
    generator = RandomFractalGenerator(dimension=4)
    
    fractal_data = []
    for i in range(n_samples):
        if i % 20 == 0:
            print(f"   ç”Ÿæˆè¿›åº¦: {i}/{n_samples}")
        
        # æ··åˆä½¿ç”¨ä¸åŒç±»å‹çš„åˆ†å½¢
        if i % 4 == 0:
            points = generator.generate_fractal_percolation(n_points, p=0.5 + 0.1*np.random.rand())
        elif i % 4 == 1:
            points = generator.generate_fractal_walk(n_points, alpha=0.4 + 0.2*np.random.rand())
        elif i % 4 == 2:
            points = generator.generate_spectral_fractal(n_points, c1=0.25)
        else:
            points = generator.generate_multifractal(n_points)
        
        fractal_data.append(points)
    
    print(f"   å®Œæˆ: ç”Ÿæˆ {n_samples} ä¸ªåˆ†å½¢æ ·æœ¬")
    
    # 3. åˆ†ææ•°æ®é›†
    print("\n[3] åˆ†æåˆ†å½¢æ•°æ®é›† (æ‹‰æ™®æ‹‰æ–¯æ–¹æ³•)")
    extractor = C1Extractor(true_c1=0.25)
    summary_lap = extractor.analyze_dataset(fractal_data, method='laplacian')
    extractor.print_report(summary_lap)
    
    # 4. ç›’è®¡æ•°æ–¹æ³•åˆ†æ
    print("\n[4] åˆ†æåˆ†å½¢æ•°æ®é›† (ç›’è®¡æ•°æ–¹æ³•)")
    summary_box = extractor.analyze_dataset(fractal_data, method='box_counting')
    extractor.print_report(summary_box)
    
    # 5. ä¿å­˜ç»“æœ
    print("\n[5] ä¿å­˜åˆ†æç»“æœ")
    extractor.save_report(summary_lap, '../data/c1_analysis_laplacian.json')
    extractor.save_report(summary_box, '../data/c1_analysis_boxcounting.json')
    
    print("\n" + "=" * 70)
    print("åˆ†æå®Œæˆ!")
    print("=" * 70)
    
    return {
        'laplacian': summary_lap,
        'box_counting': summary_box
    }


if __name__ == "__main__":
    # è¿è¡Œå°è§„æ¨¡æµ‹è¯•
    print("è¿è¡Œå°è§„æ¨¡æµ‹è¯• (10æ ·æœ¬)...")
    results = run_full_analysis(n_samples=10, n_points=200)
    
    print("\n" + "=" * 70)
    print("å‡†å¤‡è¿è¡Œå¤§è§„æ¨¡åˆ†æ (100æ ·æœ¬)...")
    print("åœ¨å‘½ä»¤è¡Œè¿è¡Œ: python c1_extractor.py --full")
    print("=" * 70)
