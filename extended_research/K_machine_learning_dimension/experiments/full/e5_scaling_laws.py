#!/usr/bin/env python3
"""
E5: æ ‡åº¦å¾‹éªŒè¯å®éªŒ
éªŒè¯d_effä¸ç½‘ç»œè§„æ¨¡ã€æ•°æ®è§„æ¨¡çš„æ ‡åº¦å…³ç³»
"""
import numpy as np
import sys
import os
import json
from typing import Dict, List
from datetime import datetime
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from lightweight.numpy_mlp import NumPyMLP, generate_synthetic_data
from lightweight.e1_effective_dimension import EffectiveDimensionEstimator


def run_e5_experiment():
    """è¿è¡ŒE5å®éªŒ"""
    print("=" * 70)
    print("E5: æ ‡åº¦å¾‹éªŒè¯å®éªŒ")
    print("=" * 70)
    
    results = {
        'timestamp': datetime.now().isoformat(),
        'scaling_laws': {}
    }
    
    # å®éªŒ1: ç½‘ç»œè§„æ¨¡æ ‡åº¦
    print("\nğŸ“Š å®éªŒ1: ç½‘ç»œè§„æ¨¡ vs æœ‰æ•ˆç»´åº¦")
    widths = [32, 64, 128, 256, 512]
    d_effs_width = []
    n_params_list = []
    
    for width in widths:
        layers = [100, width, width, 10]
        model = NumPyMLP(layers, activation='relu')
        estimator = EffectiveDimensionEstimator('fisher')
        
        n_params = model.count_parameters()
        pr = estimator.compute_participation_ratio(model)
        d_eff = pr * n_params
        
        d_effs_width.append(d_eff)
        n_params_list.append(n_params)
        print(f"   Width {width:3d}: params={n_params:6d}, d_eff={d_eff:8.1f}")
    
    results['scaling_laws']['network_size'] = {
        'widths': widths,
        'd_effs': [float(d) for d in d_effs_width],
        'n_params': n_params_list
    }
    
    # å®éªŒ2: æ•°æ®è§„æ¨¡æ ‡åº¦
    print("\nğŸ“Š å®éªŒ2: æ•°æ®è§„æ¨¡ vs æœ‰æ•ˆç»´åº¦")
    sample_sizes = [100, 500, 1000, 2000, 5000]
    d_effs_samples = []
    
    model = NumPyMLP([50, 100, 100, 5], activation='relu')
    estimator = EffectiveDimensionEstimator('fisher')
    
    for n_samples in sample_sizes:
        X, y = generate_synthetic_data(n_samples, 50, 5)
        
        # ç®€åŒ–ï¼šä½¿ç”¨å‚ä¸ç‡ä½œä¸ºd_effçš„ä»£ç†
        pr = estimator.compute_participation_ratio(model)
        d_eff = pr * model.count_parameters()
        
        d_effs_samples.append(d_eff)
        print(f"   Samples {n_samples:5d}: d_eff={d_eff:8.1f}")
    
    results['scaling_laws']['data_size'] = {
        'sample_sizes': sample_sizes,
        'd_effs': [float(d) for d in d_effs_samples]
    }
    
    # å®éªŒ3: æ·±åº¦æ ‡åº¦
    print("\nğŸ“Š å®éªŒ3: æ·±åº¦ vs æœ‰æ•ˆç»´åº¦")
    depths = [2, 3, 4, 5, 6]
    d_effs_depth = []
    
    for depth in depths:
        layers = [50] + [80] * (depth - 1) + [5]
        model = NumPyMLP(layers, activation='relu')
        estimator = EffectiveDimensionEstimator('fisher')
        
        pr = estimator.compute_participation_ratio(model)
        d_eff = pr * model.count_parameters()
        d_effs_depth.append(d_eff)
        print(f"   Depth {depth}: d_eff={d_eff:8.1f}")
    
    results['scaling_laws']['depth'] = {
        'depths': depths,
        'd_effs': [float(d) for d in d_effs_depth]
    }
    
    # ç”Ÿæˆå›¾è¡¨
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    # å›¾1: å®½åº¦æ ‡åº¦
    ax1 = axes[0]
    ax1.plot(widths, d_effs_width, 'bo-', linewidth=2, markersize=8)
    ax1.set_xlabel('Hidden Layer Width')
    ax1.set_ylabel('Effective Dimension')
    ax1.set_title('Scaling: Network Width vs d_eff')
    ax1.grid(True, alpha=0.3)
    
    # å›¾2: æ•°æ®è§„æ¨¡æ ‡åº¦
    ax2 = axes[1]
    ax2.plot(sample_sizes, d_effs_samples, 'ro-', linewidth=2, markersize=8)
    ax2.set_xlabel('Number of Samples')
    ax2.set_ylabel('Effective Dimension')
    ax2.set_title('Scaling: Data Size vs d_eff')
    ax2.grid(True, alpha=0.3)
    ax2.set_xscale('log')
    
    # å›¾3: æ·±åº¦æ ‡åº¦
    ax3 = axes[2]
    ax3.plot(depths, d_effs_depth, 'go-', linewidth=2, markersize=8)
    ax3.set_xlabel('Network Depth')
    ax3.set_ylabel('Effective Dimension')
    ax3.set_title('Scaling: Depth vs d_eff')
    ax3.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('e5_scaling_laws.png', dpi=150, bbox_inches='tight')
    print(f"\nâœ“ å›¾è¡¨å·²ä¿å­˜: e5_scaling_laws.png")
    
    # ä¿å­˜ç»“æœ
    with open('results_e5_full.json', 'w') as f:
        json.dump(results, f, indent=2)
    print(f"âœ“ ç»“æœå·²ä¿å­˜: results_e5_full.json")
    
    return results


if __name__ == '__main__':
    run_e5_experiment()
