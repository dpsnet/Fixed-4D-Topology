#!/usr/bin/env python3
"""
E2: ç½‘ç»œæ¶æ„æ¯”è¾ƒå®éªŒ (è½»é‡çº§NumPyç‰ˆæœ¬)
åˆ†æä¸åŒæ¶æ„å¯¹æœ‰æ•ˆç»´åº¦çš„å½±å“
"""
import numpy as np
import sys
import os
import json
from typing import Dict, List
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from numpy_mlp import NumPyMLP, generate_synthetic_data
from e1_effective_dimension import EffectiveDimensionEstimator


def run_e2_experiment():
    """è¿è¡ŒE2å®éªŒ"""
    print("=" * 60)
    print("E2: ç½‘ç»œæ¶æ„æ¯”è¾ƒå®éªŒ")
    print("=" * 60)
    
    results = {
        'timestamp': datetime.now().isoformat(),
        'experiments': []
    }
    
    # å®éªŒ1: æ·±åº¦å˜åŒ– (å›ºå®šå‚æ•°é‡)
    print("\nğŸ“Š å®éªŒ1: æ·±åº¦ vs æœ‰æ•ˆç»´åº¦")
    depth_configs = []
    total_params_target = 5000
    
    for depth in [2, 3, 4, 5, 6]:
        # è®¡ç®—æ¯å±‚çš„å®½åº¦ä»¥ä¿æŒæ€»å‚æ•°å¤§è‡´ç›¸åŒ
        # è¾“å…¥10, è¾“å‡º5, depthå±‚ => depth-1ä¸ªæƒé‡çŸ©é˜µ
        # ä½¿ç”¨è¿‘ä¼¼å…¬å¼
        if depth == 2:
            width = 100
        elif depth == 3:
            width = 65
        elif depth == 4:
            width = 50
        elif depth == 5:
            width = 40
        else:
            width = 35
        
        layers = [10] + [width] * (depth - 1) + [5]
        depth_configs.append({
            'name': f'Depth-{depth}',
            'layers': layers,
            'depth': depth
        })
    
    depth_results = []
    for cfg in depth_configs:
        model = NumPyMLP(cfg['layers'], activation='relu')
        estimator = EffectiveDimensionEstimator('fisher')
        
        X, y = generate_synthetic_data(200, 10, 5)
        n_params = model.count_parameters()
        pr = estimator.compute_participation_ratio(model)
        d_eff = pr * n_params
        
        depth_results.append({
            'name': cfg['name'],
            'depth': cfg['depth'],
            'total_params': n_params,
            'd_eff': float(d_eff),
            'd_eff_ratio': float(d_eff / n_params)
        })
        
        print(f"   {cfg['name']}: params={n_params}, d_eff={d_eff:.1f} "
              f"({100*d_eff/n_params:.1f}%)")
    
    results['experiments'].append({
        'name': 'Depth Variation',
        'configs': depth_results
    })
    
    # å®éªŒ2: å®½åº¦å˜åŒ–
    print("\nğŸ“Š å®éªŒ2: å®½åº¦ vs æœ‰æ•ˆç»´åº¦")
    width_configs = []
    for width in [20, 40, 60, 80, 100]:
        layers = [10, width, width, 5]
        width_configs.append({
            'name': f'Width-{width}',
            'layers': layers,
            'width': width
        })
    
    width_results = []
    for cfg in width_configs:
        model = NumPyMLP(cfg['layers'], activation='relu')
        estimator = EffectiveDimensionEstimator('fisher')
        
        X, y = generate_synthetic_data(200, 10, 5)
        n_params = model.count_parameters()
        pr = estimator.compute_participation_ratio(model)
        d_eff = pr * n_params
        
        width_results.append({
            'name': cfg['name'],
            'width': cfg['width'],
            'total_params': n_params,
            'd_eff': float(d_eff),
            'd_eff_ratio': float(d_eff / n_params)
        })
        
        print(f"   {cfg['name']}: params={n_params}, d_eff={d_eff:.1f} "
              f"({100*d_eff/n_params:.1f}%)")
    
    results['experiments'].append({
        'name': 'Width Variation',
        'configs': width_results
    })
    
    # å®éªŒ3: æ¿€æ´»å‡½æ•°æ¯”è¾ƒ
    print("\nğŸ“Š å®éªŒ3: æ¿€æ´»å‡½æ•°å½±å“")
    activations = ['relu', 'tanh', 'sigmoid']
    base_layers = [10, 50, 50, 5]
    
    activation_results = []
    for act in activations:
        model = NumPyMLP(base_layers, activation=act)
        estimator = EffectiveDimensionEstimator('fisher')
        
        X, y = generate_synthetic_data(200, 10, 5)
        n_params = model.count_parameters()
        pr = estimator.compute_participation_ratio(model)
        d_eff = pr * n_params
        
        activation_results.append({
            'activation': act,
            'total_params': n_params,
            'd_eff': float(d_eff),
            'd_eff_ratio': float(d_eff / n_params)
        })
        
        print(f"   {act}: d_eff={d_eff:.1f} ({100*d_eff/n_params:.1f}%)")
    
    results['experiments'].append({
        'name': 'Activation Function',
        'configs': activation_results
    })
    
    # å…³é”®å‘ç°
    print("\nğŸ“ˆ å…³é”®å‘ç°:")
    
    # æ·±åº¦è¶‹åŠ¿
    d_ratios = [r['d_eff_ratio'] for r in depth_results]
    print(f"   æ·±åº¦å¢åŠ æ—¶ d_eff/N è¶‹åŠ¿: {d_ratios[0]:.3f} -> {d_ratios[-1]:.3f}")
    
    # å®½åº¦è¶‹åŠ¿
    w_ratios = [r['d_eff_ratio'] for r in width_results]
    print(f"   å®½åº¦å¢åŠ æ—¶ d_eff/N è¶‹åŠ¿: {w_ratios[0]:.3f} -> {w_ratios[-1]:.3f}")
    
    # ä¿å­˜ç»“æœ
    output_file = 'results_e2_lightweight.json'
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    print(f"\nâœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return results


if __name__ == '__main__':
    run_e2_experiment()
