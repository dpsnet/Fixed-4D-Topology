# K1.1: Fisher信息矩阵理论基础

## 1. 引言

Fisher信息矩阵是连接统计推断与微分几何的核心工具，为定义神经网络有效维度奠定基础。

## 2. Fisher信息矩阵的定义

### 2.1 经典定义

对于参数化概率分布 $p(x|\theta)$，其中 $\theta \in \mathbb{R}^D$，Fisher信息矩阵定义为：

$$F_{ij}(\theta) = \mathbb{E}_{x \sim p(x|\theta)}\left[ \frac{\partial \log p(x|\theta)}{\partial \theta_i} \frac{\partial \log p(x|\theta)}{\partial \theta_j} \right]$$

等价形式：
$$F_{ij}(\theta) = -\mathbb{E}_{x \sim p(x|\theta)}\left[ \frac{\partial^2 \log p(x|\theta)}{\partial \theta_i \partial \theta_j} \right]$$

### 2.2 神经网络的Fisher信息

对于神经网络 $f_\theta: \mathcal{X} \to \mathcal{Y}$，在监督学习设置下：

**输出分布**: $p(y|x,\theta) = \mathcal{N}(y; f_\theta(x), \sigma^2 I)$

**Fisher矩阵元素**:
$$F_{ij}(\theta) = \frac{1}{N} \sum_{n=1}^N \mathbb{E}_{y \sim p(y|x_n,\theta)} \left[ \frac{\partial \log p(y|x_n,\theta)}{\partial \theta_i} \frac{\partial \log p(y|x_n,\theta)}{\partial \theta_j} \right]$$

**实用计算** (经验Fisher):
$$\hat{F}_{ij}(\theta) = \frac{1}{N} \sum_{n=1}^N \frac{\partial \ell_n}{\partial \theta_i} \frac{\partial \ell_n}{\partial \theta_j}$$

其中 $\ell_n = -\log p(y_n|x_n,\theta)$ 是样本损失。

## 3. Fisher信息的性质

### 3.1 半正定性

**引理K.1.1**: Fisher信息矩阵 $F(\theta)$ 是半正定的。

*证明*: 对于任意向量 $v \in \mathbb{R}^D$:
$$v^T F v = \mathbb{E}\left[ \left(v^T \nabla_\theta \log p\right)^2 \right] \geq 0$$

### 3.2 自然梯度

自然梯度下降：
$$\Delta \theta = -\eta F^{-1} \nabla_\theta \mathcal{L}$$

### 3.3 与KL散度的关系

$$F_{ij}(\theta) = \frac{\partial^2}{\partial \theta_i \partial \theta_j'} D_{KL}(p(\cdot|\theta) \| p(\cdot|\theta')) \Big|_{\theta'=\theta}$$

## 4. 特征值谱的性质

### 4.1 谱分布

Fisher矩阵的特征值 $\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_D \geq 0$ 反映了参数空间的几何结构。

**关键观察**:
- 大特征值: 对应敏感参数方向
- 小特征值: 对应平坦方向（冗余参数）
- 零特征值: 完全冗余

### 4.2 谱的普适性

**猜想K.1.1 (Marchenko-Pastur普适性)**: 对于宽神经网络，Fisher矩阵的特征值分布在一定条件下收敛于Marchenko-Pastur分布。

**条件**:
- 网络宽度 $N \to \infty$
- 数据独立同分布
- 激活函数满足一定正则性

## 5. 与维度的联系

### 5.1 有效维度的Fisher定义

$$d_{\text{eff}} = \frac{(\text{tr} F)^2}{\text{tr}(F^2)} = \frac{(\sum_i \lambda_i)^2}{\sum_i \lambda_i^2}$$

**性质**:
- $1 \leq d_{\text{eff}} \leq D$
- $d_{\text{eff}} = D$ 当且仅当 $F \propto I$
- $d_{\text{eff}} \ll D$ 表示高度冗余

### 5.2 与参与比的关系

有效维度等价于特征值分布的参与比：
$$d_{\text{eff}} = \left( \sum_i p_i^2 \right)^{-1}$$

其中 $p_i = \lambda_i / \sum_j \lambda_j$。

## 6. 计算考虑

### 6.1 高效计算

对于大规模神经网络，直接计算Fisher矩阵不可行 ($O(D^2)$ 内存)。

**近似方法**:
1. **对角近似**: 只保留对角元素
2. **KFAC**: Kronecker因子近似
3. **抽样估计**: 使用随机样本估计
4. **低秩近似**: $F \approx U \Sigma U^T$

### 6.2 数值稳定性

- 添加小正则: $F + \epsilon I$
- 使用SVD代替特征值分解
- 对数空间计算

## 7. 结论

Fisher信息矩阵为神经网络提供了内在的几何结构，其特征值谱直接决定了有效维度。这为后续定义和计算 $d_{\text{eff}}^{NN}$ 奠定了理论基础。

---

**严格性**: L1 (定义严格，部分性质证明)  
**下一步**: K1.2 有效维度的定义与性质
